{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for N Batches with Dynamically Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import string\n",
    "import random\n",
    "import albumentations as A\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Image Augmentation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_field(length = 0):\n",
    "    length = length if length else random.randint(2, 20)\n",
    "    field = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=length))\n",
    "    return field\n",
    "\n",
    "transform = A.Compose([\n",
    "        A.ImageCompression(quality_lower=10, p=0.1),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(p=0.8),\n",
    "            A.ISONoise(p=0.2),\n",
    "            A.MultiplicativeNoise(p=.05)\n",
    "        ], p=0.1),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.05),\n",
    "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.5),\n",
    "            A.GridDistortion(p=.5),\n",
    "            A.PiecewiseAffine(p=0.5),\n",
    "        ], p=0.5),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.Sharpen(),\n",
    "            A.Emboss(),\n",
    "            A.RandomBrightnessContrast(),            \n",
    "        ], p=0.05),\n",
    "        A.OneOf([\n",
    "            A.RandomFog(),\n",
    "            A.RandomRain(),\n",
    "            A.RandomSnow(),\n",
    "            A.RandomSunFlare(),            \n",
    "        ], p=0.1),\n",
    "        A.HueSaturationValue(p=0.01)\n",
    "    ])\n",
    "\n",
    "fonts = [\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    cv2.FONT_HERSHEY_COMPLEX,\n",
    "    cv2.FONT_HERSHEY_PLAIN,\n",
    "    cv2.FONT_HERSHEY_DUPLEX,\n",
    "    cv2.FONT_HERSHEY_TRIPLEX,\n",
    "    cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "    cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "    cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "    cv2.FONT_ITALIC]\n",
    "\n",
    "def generate_target_dictionary():\n",
    "    with open('data_dictionary.json') as data_dict:\n",
    "        categories = json.load(data_dict)['target_data']\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables we will need for augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_directory = 'templates_img'\n",
    "text_locations = json.load(open('text_locations.json', 'r'))\n",
    "image_dir =  \"data/\"\n",
    "backgrounds_dir = 'image_backgrounds'\n",
    "\n",
    "categories = generate_target_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models():\n",
    "    models={}\n",
    "    nb_full = BernoulliNB(alpha=10)\n",
    "    for key in categories.keys():\n",
    "        models[key] =  BernoulliNB(alpha=0.1)\n",
    "    return models, nb_full\n",
    "\n",
    "def fit_on_batch(x,y, models, nb_full):\n",
    "    nb_full.partial_fit(x, y, classes=[0,1,2,3,4,5,6,7])\n",
    "    for key in categories.keys():\n",
    "        target_class = categories[key]\n",
    "        models[key].partial_fit(x, y==target_class, classes=[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_batch(x,y, models, nb_full, batch):\n",
    "\n",
    "    results = np.zeros((y.shape[0],8))\n",
    "    nb_full_results = np.zeros((y.shape[0],8))\n",
    "\n",
    "    y_pred = nb_full.predict_proba(x)[:]\n",
    "    nb_full_results = y_pred\n",
    "    for key in categories.keys():\n",
    "        y_pred = models[key].predict_proba(x)[:,0]\n",
    "        results[:,categories[key]] = y_pred\n",
    "\n",
    "    test = np.copy(y)\n",
    "    test2 = np.copy(y)\n",
    "    test3 = np.copy(y)\n",
    "\n",
    "    added_results = np.zeros(nb_full_results.shape)\n",
    "\n",
    "    for  i in range(results[:,0].shape[0]):\n",
    "        added_results[i,:] = results[i,:] + (np.absolute(nb_full_results[i,:]-1)/1.0e+200)\n",
    "        max = np.where(results[i,:] == np.amin(results[i,:].reshape(8)))[0]\n",
    "        max2 = np.where(added_results[i,:] == np.amin(added_results[i,:].reshape(8)))[0]\n",
    "        max3 = np.where(nb_full_results[i,:]== np.amax(nb_full_results[i,:].reshape(8)))[0]\n",
    "        if len(max)>1:\n",
    "            test[i] = 8\n",
    "        else:\n",
    "            test[i]=max[0]\n",
    "\n",
    "        if len(max2)>1:\n",
    "            test2[i] = 8\n",
    "        else:\n",
    "            test2[i]=max2[0]\n",
    "\n",
    "        if len(max3)>1:\n",
    "            test3[i] = 8\n",
    "        else:\n",
    "            test3[i]=max3[0]\n",
    "\n",
    "    with open(\"training_log.txt\", \"a\") as file:\n",
    "        \n",
    "        file.writelines('\\n\\n\\n')\n",
    "        file.writelines('*|'*50)\n",
    "        file.writelines('\\n')\n",
    "        file.writelines('*|'*50)\n",
    "        file.writelines('\\n')\n",
    "        file.writelines('*|'*50)\n",
    "        file.writelines('\\n\\n')\n",
    "        file.writelines(f'\\t\\t\\t\\t\\tIteration:{batch}')\n",
    "\n",
    "\n",
    "        y_pred = test\n",
    "        mask = y_pred != 8\n",
    "\n",
    "        file.writelines('\\n\\nBase OVR Ensemble')\n",
    "        file.writelines(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "        file.writelines(f'\\n\\tAccuracy:\\t{accuracy_score(y, y_pred)}')\n",
    "        file.writelines(f'\\n\\tPrecision:\\t{precision_score(y, y_pred, average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tRecall:\\t{recall_score(y, y_pred, average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tF1:\\t{f1_score(y, y_pred, average=\"macro\")}\\n')\n",
    "        file.writelines(str(confusion_matrix(y, y_pred)))\n",
    "\n",
    "        file.writelines('\\n\\n')\n",
    "        file.writelines(\"===\"*20)\n",
    "\n",
    "        file.writelines('\\n\\nFiltered OVR Ensemble')\n",
    "        file.writelines(f'\\n\\nData Size:\\t{len(y_pred[mask])}/{len(y_pred)}')\n",
    "        file.writelines(f'\\n\\tAccuracy:\\t{accuracy_score(y[mask], y_pred[mask])}')\n",
    "        file.writelines(f'\\n\\tPrecision:\\t{precision_score(y[mask], y_pred[mask], average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tRecall:\\t{recall_score(y[mask], y_pred[mask], average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tF1:\\t{f1_score(y[mask], y_pred[mask], average=\"macro\")}\\n')\n",
    "        file.writelines(str(confusion_matrix(y[mask], y_pred[mask])))\n",
    "        \n",
    "        file.writelines('\\n\\n')\n",
    "        file.writelines(\"===\"*20)\n",
    "\n",
    "        y_pred = test3\n",
    "        file.writelines('\\n\\nBase Multiclass')\n",
    "        file.writelines(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "        file.writelines(f'\\n\\tAccuracy:\\t{accuracy_score(y, y_pred)}')\n",
    "        file.writelines(f'\\n\\tPrecision:\\t{precision_score(y, y_pred, average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tRecall:\\t{recall_score(y, y_pred, average=\"macro\")}')\n",
    "        file.writelines(f'\\n\\tF1:\\t{f1_score(y, y_pred, average=\"macro\")}\\n')\n",
    "        file.writelines(str(confusion_matrix(y, y_pred)))\n",
    "\n",
    "def checkpoint(models, nb_full, iteration):\n",
    "    with open(f'models/EnsembleModels_{iteration}', 'ab') as file:\n",
    "        pickle.dump(models, file)       \n",
    "\n",
    "    with open(f'models/MulticlassModel_{iteration}', 'ab') as file:\n",
    "        pickle.dump(nb_full, file)                       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backgrounds():\n",
    "    for filename in os.listdir(backgrounds_dir):\n",
    "        backgrounds = []\n",
    "        img = cv2.imread(backgrounds_dir+ '/'+filename, 1)\n",
    "        backgrounds.append(img)\n",
    "    return backgrounds\n",
    "\n",
    "\n",
    "\n",
    "def agument_image(image, backgrounds):\n",
    "    background_img = backgrounds[random.randint(0, len(backgrounds))-1]\n",
    "    img = image\n",
    "    for loc in doc_info:\n",
    "        font = random.choice(fonts)\n",
    "        cv2.putText(img, generate_random_field(),\n",
    "                    (int(loc['x']),int(loc['y'])), font,\n",
    "                    1, (0, 0, 0), 1)\n",
    "    # resize(210,275)\n",
    "    x_size = random.randint(-150,400)\n",
    "    y_size = random.randint(-150,400)\n",
    "    x_size = x_size if x_size > 150 else 0\n",
    "    y_size = y_size if y_size > 150 else 0\n",
    "    x_offset = int(x_size/1.5)\n",
    "    y_offset = int(y_size/1.5)\n",
    "    background_img = cv2.resize(background_img, (850+abs(x_size), 1100+abs(y_size))) \n",
    "\n",
    "    background_img[y_offset:y_offset+img.shape[0], x_offset:x_offset+img.shape[1]] = img\n",
    "    transformed = transform(image=cv2.resize(background_img, (200,200)))\n",
    "    img = transformed['image']\n",
    "\n",
    "    # img = cv2.resize(img, (100,100))\n",
    "    # img = cv2.resize(img, (200,200))\n",
    "\n",
    "    # img = cv2.resize(img, (850+abs(x_size), 1100+abs(y_size)))\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    return img/255\n",
    "\n",
    "\n",
    "for filename in text_locations:\n",
    "    if text_locations[filename] != {}:\n",
    "        image = cv2.imread(template_directory+ '/'+filename, 1)\n",
    "        image = cv2.resize(image, (850, 1100)) \n",
    "\n",
    "        doc_info = text_locations[filename]\n",
    "        for i in range(3):\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = (280*360)\n",
    "dim_shape (280,360)\n",
    "\n",
    "def main(batch_size, num_batches, test_frequency, models=False, nb_full=False):\n",
    "    backgrounds = load_backgrounds()\n",
    "    chunk = batch_size//8\n",
    "    \n",
    "    if not models:\n",
    "        models, nb_full = generate_models()\n",
    "    \n",
    "    for iteration in range(num_batches):\n",
    "        print(f'\\nIteration:\\t{iteration}')\n",
    "        x = np.zeros(shape=(batch_size,200*200))\n",
    "        y = np.zeros((batch_size,))\n",
    "        index = 0\n",
    "        #generate our data\n",
    "        for filename in text_locations:\n",
    "            \n",
    "            if text_locations[filename] != {}:\n",
    "                image = cv2.imread(template_directory+ '/'+filename, 1)\n",
    "                image = cv2.resize(image, (850, 1100)) \n",
    "\n",
    "                doc_info = text_locations[filename]\n",
    "                for row in range(chunk):\n",
    "                    print(index,end='\\r', flush=True)\n",
    "                    img = agument_image(image, backgrounds)\n",
    "                    x[index] =  np.reshape(img, (200*200))\n",
    "                    y[index] = categories[filename[:4]]\n",
    "                    index = index + 1\n",
    "        \n",
    "\n",
    "        if iteration%test_frequency == 0 and iteration!= 0:\n",
    "            test_on_batch(x, y, models, nb_full, iteration)\n",
    "            checkpoint(models, nb_full, iteration)\n",
    "        else:\n",
    "            fit_on_batch(x, y, models, nb_full)\n",
    "    return models, nb_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_full =  pickle.load(open('models/MulticlassModel_6', 'rb'))\n",
    "models =  pickle.load(open('models/EnsembleModels_6', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:\t0\n",
      "7999\n",
      "Iteration:\t1\n",
      "7999\n",
      "Iteration:\t2\n",
      "7999\n",
      "Iteration:\t3\n",
      "7999\n",
      "Iteration:\t4\n",
      "7999\n",
      "Iteration:\t5\n",
      "7999\n",
      "Iteration:\t6\n",
      "7999\n",
      "Iteration:\t7\n",
      "7999\n",
      "Iteration:\t8\n",
      "7999\n",
      "Iteration:\t9\n",
      "7999\n",
      "Iteration:\t10\n",
      "7999\n",
      "Iteration:\t11\n",
      "7999\n",
      "Iteration:\t12\n",
      "7999\n",
      "Iteration:\t13\n",
      "7999\n",
      "Iteration:\t14\n",
      "7999\n",
      "Iteration:\t15\n",
      "7999\n",
      "Iteration:\t16\n",
      "7999\n",
      "Iteration:\t17\n",
      "7999\n",
      "Iteration:\t18\n",
      "7999\n",
      "Iteration:\t19\n",
      "7999\n",
      "Iteration:\t20\n",
      "7999\n",
      "Iteration:\t21\n",
      "7999\n",
      "Iteration:\t22\n",
      "7999\n",
      "Iteration:\t23\n",
      "7999\n",
      "Iteration:\t24\n",
      "7999\n",
      "Iteration:\t25\n",
      "7999\n",
      "Iteration:\t26\n",
      "3525\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/patrick/classification_project/online_training.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m models, nb_full \u001b[39m=\u001b[39m main(batch_size\u001b[39m=\u001b[39;49m\u001b[39m8000\u001b[39;49m, num_batches\u001b[39m=\u001b[39;49m\u001b[39m61\u001b[39;49m, test_frequency\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/home/patrick/classification_project/online_training.ipynb Cell 15\u001b[0m in \u001b[0;36mmain\u001b[0;34m(batch_size, num_batches, test_frequency, models, nb_full)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(chunk):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(index,end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     img \u001b[39m=\u001b[39m agument_image(image, backgrounds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x[index] \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39mreshape(img, (\u001b[39m200\u001b[39m\u001b[39m*\u001b[39m\u001b[39m200\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     y[index] \u001b[39m=\u001b[39m categories[filename[:\u001b[39m4\u001b[39m]]\n",
      "\u001b[1;32m/home/patrick/classification_project/online_training.ipynb Cell 15\u001b[0m in \u001b[0;36magument_image\u001b[0;34m(image, backgrounds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m background_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(background_img, (\u001b[39m850\u001b[39m\u001b[39m+\u001b[39m\u001b[39mabs\u001b[39m(x_size), \u001b[39m1100\u001b[39m\u001b[39m+\u001b[39m\u001b[39mabs\u001b[39m(y_size))) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m background_img[y_offset:y_offset\u001b[39m+\u001b[39mimg\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], x_offset:x_offset\u001b[39m+\u001b[39mimg\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m img\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m transformed \u001b[39m=\u001b[39m transform(image\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mresize(background_img, (\u001b[39m200\u001b[39;49m,\u001b[39m200\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m img \u001b[39m=\u001b[39m transformed[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# img = cv2.resize(img, (100,100))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# img = cv2.resize(img, (200,200))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/patrick/classification_project/online_training.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# img = cv2.resize(img, (850+abs(x_size), 1100+abs(y_size)))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/core/composition.py:205\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    202\u001b[0m     p\u001b[39m.\u001b[39mpreprocess(data)\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m idx, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 205\u001b[0m     data \u001b[39m=\u001b[39m t(force_apply\u001b[39m=\u001b[39;49mforce_apply, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    208\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/core/composition.py:309\u001b[0m, in \u001b[0;36mOneOf.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    307\u001b[0m     idx: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m random_utils\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms), p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms_ps)\n\u001b[1;32m    308\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms[idx]\n\u001b[0;32m--> 309\u001b[0m     data \u001b[39m=\u001b[39m t(force_apply\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    310\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:98\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             warn(\n\u001b[1;32m     94\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_class_fullname() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m because its\u001b[39m\u001b[39m'\u001b[39m\u001b[39m params depend on targets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         kwargs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_key][\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)] \u001b[39m=\u001b[39m deepcopy(params)\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_with_params(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:111\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     target_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    110\u001b[0m     target_dependencies \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dependence\u001b[39m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 111\u001b[0m     res[key] \u001b[39m=\u001b[39m target_function(arg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtarget_dependencies))\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     res[key] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/augmentations/geometric/transforms.py:894\u001b[0m, in \u001b[0;36mPiecewiseAffine.apply\u001b[0;34m(self, img, matrix, **params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m    892\u001b[0m     \u001b[39mself\u001b[39m, img: np\u001b[39m.\u001b[39mndarray, matrix: skimage\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPiecewiseAffineTransform \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    893\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mpiecewise_affine(img, matrix, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcval)\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/augmentations/functional.py:142\u001b[0m, in \u001b[0;36mclipped.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m dtype \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    141\u001b[0m maxval \u001b[39m=\u001b[39m MAX_VALUES_BY_DTYPE\u001b[39m.\u001b[39mget(dtype, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m clip(func(img, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), dtype, maxval)\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:668\u001b[0m, in \u001b[0;36mpiecewise_affine\u001b[0;34m(img, matrix, interpolation, mode, cval)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m@clipped\u001b[39m\n\u001b[1;32m    661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpiecewise_affine\u001b[39m(\n\u001b[1;32m    662\u001b[0m     img: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m     cval: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m--> 668\u001b[0m     \u001b[39mreturn\u001b[39;00m skimage\u001b[39m.\u001b[39;49mtransform\u001b[39m.\u001b[39;49mwarp(\n\u001b[1;32m    669\u001b[0m         img, matrix, order\u001b[39m=\u001b[39;49minterpolation, mode\u001b[39m=\u001b[39;49mmode, cval\u001b[39m=\u001b[39;49mcval, preserve_range\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, output_shape\u001b[39m=\u001b[39;49mimg\u001b[39m.\u001b[39;49mshape\n\u001b[1;32m    670\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/skimage/transform/_warps.py:997\u001b[0m, in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    993\u001b[0m     ndi_mode \u001b[39m=\u001b[39m _to_ndimage_mode(mode)\n\u001b[1;32m    994\u001b[0m     warped \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39mmap_coordinates(image, coords, prefilter\u001b[39m=\u001b[39mprefilter,\n\u001b[1;32m    995\u001b[0m                                  mode\u001b[39m=\u001b[39mndi_mode, order\u001b[39m=\u001b[39morder, cval\u001b[39m=\u001b[39mcval)\n\u001b[0;32m--> 997\u001b[0m _clip_warp_output(image, warped, mode, cval, clip)\n\u001b[1;32m    999\u001b[0m \u001b[39mreturn\u001b[39;00m warped\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/skimage/transform/_warps.py:720\u001b[0m, in \u001b[0;36m_clip_warp_output\u001b[0;34m(input_image, output_image, mode, cval, clip)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m\"\"\"Clip output image to range of values of input image.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \n\u001b[1;32m    695\u001b[0m \u001b[39mNote that this function modifies the values of `output_image` in-place\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m \n\u001b[1;32m    718\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[39mif\u001b[39;00m clip:\n\u001b[0;32m--> 720\u001b[0m     min_val \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmin(input_image)\n\u001b[1;32m    721\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(min_val):\n\u001b[1;32m    722\u001b[0m         \u001b[39m# NaNs detected, use NaN-safe min/max\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         min_func \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2916\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2800\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[1;32m   2801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2802\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2803\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[1;32m   2915\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2916\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2917\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/anaconda3/envs/classification/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models, nb_full = main(batch_size=8000, num_batches=61, test_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_full.feature_log_prob_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3.47265635, -3.47265635, -3.41858912, ..., -3.41858912,\n",
       "        -3.36729583, -3.47265635],\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718],\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718],\n",
       "       ...,\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718],\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718],\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0e1bddb7ed37f67f576e4a6a21b2408ebab9a006050dc6d038d31036c144c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
