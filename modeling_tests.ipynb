{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Let's load our data.\n",
    "Starting with the smallest dataset for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 360)\n",
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "x = np.memmap('data/gray_data_360', mode='r', shape = (150000,360))\n",
    "# x = np.load('data/gray_data_20')\n",
    "y = np.memmap('data/image_target.npy', mode='r', shape = (150000,))\n",
    "x_test = np.memmap('data/test_gray_data_360.npy', mode='r', shape = (50000,360))\n",
    "y_test = np.memmap('data/test_target.npy', mode='r', shape = (50000))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "# y = y == 2\n",
    "# y = y.astype(int)\n",
    "# y_test = y_test == 2\n",
    "# y_test = y_test.astype(int)\n",
    "x = x/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"target_data\": {\n",
    "\"Inco\": 2, \n",
    "\"Teac\": 1, \n",
    "\"Cons\": 0, \n",
    "\"Publ\": 4, \n",
    "\"Econ\": 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 360)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, y[0], test_size=0.2, stratify=y)\n",
    "print(X_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "K nearest neighbors\n",
    "\n",
    "~~~\n",
    "Accuracy:  0.218\n",
    "Precision:\t0.21878291972161956\n",
    "Recall:\t0.21799999999999997\n",
    "F1:\t0.2158672632176471\n",
    "array([[1658, 1364, 1110,  993,  875],\n",
    "       [1541, 1545, 1138,  965,  811],\n",
    "       [1557, 1340, 1286,  961,  856],\n",
    "       [1567, 1341, 1192, 1059,  841],\n",
    "       [1590, 1370, 1090,  958,  992]])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.24358\n",
      "Precision:\t0.24554351463873764\n",
      "Recall:\t0.24358\n",
      "F1:\t0.24218200464796627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2987, 2054, 2038, 1411, 1510],\n",
       "       [2528, 2634, 1934, 1425, 1479],\n",
       "       [2489, 2058, 2550, 1395, 1508],\n",
       "       [2430, 2079, 2004, 2016, 1471],\n",
       "       [2529, 2059, 1985, 1435, 1992]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=40, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.20534\n",
    "Precision:\t0.20556761017314962\n",
    "Recall:\t0.20534\n",
    "F1:\t0.20329858294811992\n",
    "array([[1883, 2415, 2303, 2030, 1369],\n",
    "       [1716, 2481, 2369, 2067, 1367],\n",
    "       [1721, 2372, 2430, 2124, 1353],\n",
    "       [1661, 2522, 2348, 2085, 1384],\n",
    "       [1718, 2400, 2401, 2093, 1388]])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20122\n",
      "Precision:\t0.20127568026703954\n",
      "Recall:\t0.20122\n",
      "F1:\t0.201213063006084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2045, 2050, 2029, 1976, 1900],\n",
       "       [2085, 2051, 1946, 2007, 1911],\n",
       "       [2006, 2108, 2013, 2075, 1798],\n",
       "       [1994, 2006, 1950, 1995, 2055],\n",
       "       [2016, 2188, 1924, 1915, 1957]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l2'],\n",
       "                         'solver': ['liblinear', 'newton-cg']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"], \"solver\":['liblinear','newton-cg']}\n",
    "lr=LogisticRegression()\n",
    "lr_cv=GridSearchCV(lr,grid,cv=3,scoring='f1_macro')\n",
    "lr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.900504</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.035245</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.225605</td>\n",
       "      <td>0.226902</td>\n",
       "      <td>0.227548</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.817865</td>\n",
       "      <td>0.284753</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2', 'solver': 'libli...</td>\n",
       "      <td>0.225301</td>\n",
       "      <td>0.226770</td>\n",
       "      <td>0.227442</td>\n",
       "      <td>0.226504</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.882647</td>\n",
       "      <td>0.177206</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.226746</td>\n",
       "      <td>0.227417</td>\n",
       "      <td>0.226488</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.669345</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>0.035962</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.225250</td>\n",
       "      <td>0.226771</td>\n",
       "      <td>0.227417</td>\n",
       "      <td>0.226479</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.738656</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.034326</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.225310</td>\n",
       "      <td>0.227052</td>\n",
       "      <td>0.227073</td>\n",
       "      <td>0.226478</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "4       17.900504      0.358100         0.035245        0.000225     0.1   \n",
       "10      20.817865      0.284753         0.036785        0.002518   100.0   \n",
       "12      20.882647      0.177206         0.035058        0.000802  1000.0   \n",
       "8       20.669345      0.030453         0.035962        0.000987    10.0   \n",
       "2       13.738656      0.031851         0.034326        0.000109    0.01   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "4             l2    liblinear   \n",
       "10            l2    liblinear   \n",
       "12            l2    liblinear   \n",
       "8             l2    liblinear   \n",
       "2             l2    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "4   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.225605   \n",
       "10  {'C': 100.0, 'penalty': 'l2', 'solver': 'libli...           0.225301   \n",
       "12  {'C': 1000.0, 'penalty': 'l2', 'solver': 'libl...           0.225300   \n",
       "8   {'C': 10.0, 'penalty': 'l2', 'solver': 'liblin...           0.225250   \n",
       "2   {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...           0.225310   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "4            0.226902           0.227548         0.226685        0.000808   \n",
       "10           0.226770           0.227442         0.226504        0.000894   \n",
       "12           0.226746           0.227417         0.226488        0.000883   \n",
       "8            0.226771           0.227417         0.226479        0.000909   \n",
       "2            0.227052           0.227073         0.226478        0.000826   \n",
       "\n",
       "    rank_test_score  \n",
       "4                 1  \n",
       "10                2  \n",
       "12                3  \n",
       "8                 4  \n",
       "2                 5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(lr_cv.cv_results_)\n",
    "res.sort_values(by='rank_test_score', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.22542\n",
      "Precision:\t0.2254166168175497\n",
      "Recall:\t0.22542\n",
      "F1:\t0.2253968045432373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2162, 2033, 1902, 1918, 1985],\n",
       "       [1840, 2305, 1941, 1966, 1948],\n",
       "       [1940, 2027, 2243, 1851, 1939],\n",
       "       [1917, 1954, 1948, 2247, 1934],\n",
       "       [1923, 1994, 1928, 1841, 2314]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1,penalty='l2',solver='newton-cg')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.20046\n",
    "Precision:\t0.20043461791314954\n",
    "Recall:\t0.20046\n",
    "F1:\t0.20025358642806665\n",
    "array([[2236, 2066, 2003, 1891, 1804],\n",
    "       [2183, 2051, 1982, 1969, 1815],\n",
    "       [2319, 1968, 1953, 1921, 1839],\n",
    "       [2110, 2065, 2062, 1937, 1826],\n",
    "       [2149, 2070, 2005, 1930, 1846]])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20424\n",
      "Precision:\t0.2042618378400461\n",
      "Recall:\t0.20423999999999998\n",
      "F1:\t0.2042340751277937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2058, 1995, 1970, 1964, 2013],\n",
       "       [1953, 2067, 1935, 1938, 2107],\n",
       "       [2017, 2027, 1978, 1943, 2035],\n",
       "       [1973, 1974, 1914, 2046, 2093],\n",
       "       [1950, 1971, 1946, 2070, 2063]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'min_samples_split': [2, 6, 14, 32, 64],\n",
       "                         'random_state': [42, None]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid={\"criterion\":[\"gini\",'entropy'],'min_samples_split':[2,6,14,32,64], 'random_state':[42, None] }\n",
    "dt=DecisionTreeClassifier()\n",
    "dt_cv=GridSearchCV(dt,grid,cv=3,scoring='f1_macro')\n",
    "dt_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.550681</td>\n",
       "      <td>0.081907</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_split': 2, ...</td>\n",
       "      <td>0.214716</td>\n",
       "      <td>0.216214</td>\n",
       "      <td>0.217456</td>\n",
       "      <td>0.216128</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.721425</td>\n",
       "      <td>0.208265</td>\n",
       "      <td>0.032089</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_split': 2, ...</td>\n",
       "      <td>0.217047</td>\n",
       "      <td>0.213960</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.216042</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.708585</td>\n",
       "      <td>0.046757</td>\n",
       "      <td>0.031218</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_split': ...</td>\n",
       "      <td>0.217093</td>\n",
       "      <td>0.212089</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.489973</td>\n",
       "      <td>0.109457</td>\n",
       "      <td>0.030265</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>entropy</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_split': ...</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.213864</td>\n",
       "      <td>0.218960</td>\n",
       "      <td>0.215874</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.453665</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>entropy</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_split': ...</td>\n",
       "      <td>0.215472</td>\n",
       "      <td>0.213849</td>\n",
       "      <td>0.218251</td>\n",
       "      <td>0.215857</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.550681      0.081907         0.029533        0.002559   \n",
       "1        2.721425      0.208265         0.032089        0.003546   \n",
       "12       3.708585      0.046757         0.031218        0.002523   \n",
       "15       3.489973      0.109457         0.030265        0.000409   \n",
       "14       3.453665      0.101807         0.029545        0.002062   \n",
       "\n",
       "   param_criterion param_min_samples_split param_random_state  \\\n",
       "0             gini                       2                 42   \n",
       "1             gini                       2               None   \n",
       "12         entropy                       6                 42   \n",
       "15         entropy                      14               None   \n",
       "14         entropy                      14                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'min_samples_split': 2, ...           0.214716   \n",
       "1   {'criterion': 'gini', 'min_samples_split': 2, ...           0.217047   \n",
       "12  {'criterion': 'entropy', 'min_samples_split': ...           0.217093   \n",
       "15  {'criterion': 'entropy', 'min_samples_split': ...           0.214798   \n",
       "14  {'criterion': 'entropy', 'min_samples_split': ...           0.215472   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.216214           0.217456         0.216128        0.001120   \n",
       "1            0.213960           0.217119         0.216042        0.001472   \n",
       "12           0.212089           0.218641         0.215941        0.002796   \n",
       "15           0.213864           0.218960         0.215874        0.002215   \n",
       "14           0.213849           0.218251         0.215857        0.001817   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 2  \n",
       "12                3  \n",
       "15                4  \n",
       "14                5  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(dt_cv.cv_results_)\n",
    "res.sort_values(by='rank_test_score', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20046\n",
      "Precision:\t0.20043461791314954\n",
      "Recall:\t0.20046\n",
      "F1:\t0.20025358642806665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2236, 2066, 2003, 1891, 1804],\n",
       "       [2183, 2051, 1982, 1969, 1815],\n",
       "       [2319, 1968, 1953, 1921, 1839],\n",
       "       [2110, 2065, 2062, 1937, 1826],\n",
       "       [2149, 2070, 2005, 1930, 1846]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', min_samples_split=64, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.20516\n",
    "Precision:\t0.2051212463423299\n",
    "Recall:\t0.20515999999999995\n",
    "F1:\t0.20510088356551712\n",
    "array([[2072, 2056, 2049, 1907, 1916],\n",
    "       [2066, 2011, 2039, 1894, 1990],\n",
    "       [2003, 1998, 2069, 1880, 2050],\n",
    "       [1978, 2028, 2048, 1920, 2026],\n",
    "       [2046, 1988, 1930, 1850, 2186]])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.22382\n",
      "Precision:\t0.22412490535754753\n",
      "Recall:\t0.22382\n",
      "F1:\t0.2236522203554892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2360, 2040, 1979, 1786, 1835],\n",
       "       [2174, 2392, 1893, 1830, 1711],\n",
       "       [2225, 2040, 2280, 1734, 1721],\n",
       "       [2160, 2034, 1938, 2112, 1756],\n",
       "       [2175, 2003, 1992, 1783, 2047]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.2027\n",
      "Precision:\t0.20268895335050835\n",
      "Recall:\t0.20270000000000002\n",
      "F1:\t0.202622174130087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2083, 2024, 2019, 1873, 2001],\n",
       "       [2058, 2068, 1977, 1889, 2008],\n",
       "       [2100, 2035, 1959, 1889, 2017],\n",
       "       [2013, 2153, 1972, 1890, 1972],\n",
       "       [2099, 2041, 1928, 1797, 2135]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', min_samples_split=64, random_state=42, max_features=4, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20516\n",
      "Precision:\t0.2051212463423299\n",
      "Recall:\t0.20515999999999995\n",
      "F1:\t0.20510088356551712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2072, 2056, 2049, 1907, 1916],\n",
       "       [2066, 2011, 2039, 1894, 1990],\n",
       "       [2003, 1998, 2069, 1880, 2050],\n",
       "       [1978, 2028, 2048, 1920, 2026],\n",
       "       [2046, 1988, 1930, 1850, 2186]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_samples_split=32, max_features=4, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.2025\n",
    "Precision:\t0.2025738072573832\n",
    "Recall:\t0.20249999999999999\n",
    "F1:\t0.20229736964345638\n",
    "array([[2208, 2007, 1772, 2025, 1988],\n",
    "       [2150, 2057, 1745, 2094, 1954],\n",
    "       [2183, 1989, 1815, 2045, 1968],\n",
    "       [2207, 2052, 1764, 2063, 1914],\n",
    "       [2219, 1989, 1775, 2035, 1982]])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.23016\n",
      "Precision:\t0.23081969522554133\n",
      "Recall:\t0.23015999999999998\n",
      "F1:\t0.22896671987642522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2708, 1889, 1967, 1373, 2063],\n",
       "       [2247, 2255, 2075, 1400, 2023],\n",
       "       [2353, 1917, 2411, 1357, 1962],\n",
       "       [2310, 1993, 1986, 1728, 1983],\n",
       "       [2292, 1921, 2042, 1339, 2406]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier( \n",
    "                        n_estimators=30000,\n",
    "                        max_depth=4,\n",
    "                        objective='multi:softmax', #new objective\n",
    "                        learning_rate=.05, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=3,\n",
    "                        colsample_bytree=.8,\n",
    "                        use_label_encoder=False\n",
    "                       )\n",
    "\n",
    "eval_set=[(X_train,y_train),(X_val,y_val)]\n",
    "fit_model = gbm.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='merror',\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=False\n",
    "                   )\n",
    "\n",
    "y_pred = gbm.predict(x_test)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbm = xgb.XGBClassifier(use_label_encoder=False)\n",
    "# # grid={'max_depth': [2, 6, 12],'n_estimators': [50, 100, 200], 'learning_rate':[0.3,.05],\n",
    "# #         'objective':['multi:softmax', 'multi:softprob'],'colsample_bytree':[0.2,0.5,0.8]}\n",
    "# grid={'max_depth': [2, 12],'n_estimators': [50, 200],\n",
    "#         'objective':['multi:softmax'],'colsample_bytree':[0.8]}\n",
    "# gbm_cv=GridSearchCV(gbm,grid,cv=3,scoring='f1_macro', n_jobs=-1)\n",
    "# gbm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame(gbm_cv.cv_results_)\n",
    "# res.sort_values(by='rank_test_score', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20294\n",
      "Precision:\t0.20297739832653744\n",
      "Recall:\t0.20293999999999998\n",
      "F1:\t0.20288853644668597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2018, 2166, 1941, 1913, 1962],\n",
       "       [2039, 2060, 1925, 1933, 2043],\n",
       "       [2146, 2073, 1923, 1900, 1958],\n",
       "       [2052, 2059, 1884, 1959, 2046],\n",
       "       [2040, 2044, 1828, 1901, 2187]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier( \n",
    "                        n_estimators=200,\n",
    "                        max_depth=12,\n",
    "                        objective='multi:softmax', #new objective\n",
    "                        learning_rate=.03, \n",
    "                        min_child_weight=3,\n",
    "                        colsample_bytree=.4,\n",
    "                        use_label_encoder=False\n",
    "                       )\n",
    "\n",
    "eval_set=[(X_train,y_train),(X_val,y_val)]\n",
    "fit_model = gbm.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='merror',\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=False\n",
    "                   )\n",
    "\n",
    "y_pred = gbm.predict(x_test)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.2025\n",
    "Precision:\t0.2025738072573832\n",
    "Recall:\t0.20249999999999999\n",
    "F1:\t0.20229736964345638\n",
    "array([[2208, 2007, 1772, 2025, 1988],\n",
    "       [2150, 2057, 1745, 2094, 1954],\n",
    "       [2183, 1989, 1815, 2045, 1968],\n",
    "       [2207, 2052, 1764, 2063, 1914],\n",
    "       [2219, 1989, 1775, 2035, 1982]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.22816\n",
      "Precision:\t0.22821810148540583\n",
      "Recall:\t0.22816\n",
      "F1:\t0.22813622601864608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2231, 2018, 1889, 2031, 1831],\n",
       "       [1898, 2312, 1925, 2022, 1843],\n",
       "       [1963, 1956, 2280, 1984, 1817],\n",
       "       [1897, 1970, 1936, 2367, 1830],\n",
       "       [1941, 1944, 1864, 2033, 2218]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.20268\n",
    "Precision:\t0.20283658864486426\n",
    "Recall:\t0.20268000000000003\n",
    "F1:\t0.200649114635904\n",
    "array([[1715, 2331, 2302, 2231, 1421],\n",
    "       [1595, 2355, 2343, 2270, 1437],\n",
    "       [1571, 2266, 2376, 2342, 1445],\n",
    "       [1530, 2449, 2272, 2286, 1463],\n",
    "       [1601, 2318, 2356, 2323, 1402]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.22568\n",
      "Precision:\t0.2266351415659172\n",
      "Recall:\t0.22568000000000002\n",
      "F1:\t0.2244179949029156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1999, 2014, 2597, 1769, 1621],\n",
       "       [1703, 2310, 2639, 1734, 1614],\n",
       "       [1733, 2032, 2931, 1707, 1597],\n",
       "       [1732, 1967, 2658, 2083, 1560],\n",
       "       [1689, 2020, 2618, 1712, 1961]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Models\n",
    "\n",
    "~~~\n",
    "Accuracy:\t0.2025\n",
    "Precision:\t0.2025738072573832\n",
    "Recall:\t0.20249999999999999\n",
    "F1:\t0.20229736964345638\n",
    "array([[2208, 2007, 1772, 2025, 1988],\n",
    "       [2150, 2057, 1745, 2094, 1954],\n",
    "       [2183, 1989, 1815, 2045, 1968],\n",
    "       [2207, 2052, 1764, 2063, 1914],\n",
    "       [2219, 1989, 1775, 2035, 1982]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.23224\n",
      "Precision:\t0.23481330943705955\n",
      "Recall:\t0.23224\n",
      "F1:\t0.22896118897966494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3172, 2208, 1839, 1510, 1271],\n",
       "       [2823, 2693, 1810, 1452, 1222],\n",
       "       [2825, 2251, 2257, 1457, 1210],\n",
       "       [2810, 2253, 1829, 1898, 1210],\n",
       "       [2851, 2219, 1844, 1494, 1592]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create voting classifier\n",
    "model_list = [\n",
    "    ('knn', knn),\n",
    "    ('lr', lr),\n",
    "    ('dt', dt),\n",
    "    ('rf', rf),\n",
    "    ('nb', gnb)\n",
    "]\n",
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard', #<-- sklearn calls this hard voting\n",
    "                                    n_jobs=-1)\n",
    "voting_classifer.fit(X_train, y_train)\n",
    "y_pred = voting_classifer.predict(x_test)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.22386\n",
      "Precision:\t0.22386667901343751\n",
      "Recall:\t0.22386\n",
      "F1:\t0.2238526081838068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2181, 1963, 1947, 1952, 1957],\n",
       "       [1875, 2268, 1936, 1969, 1952],\n",
       "       [1909, 1985, 2248, 1919, 1939],\n",
       "       [1897, 2022, 1868, 2228, 1985],\n",
       "       [1931, 1926, 1888, 1987, 2268]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft', #<-- sklearn calls this hard voting\n",
    "                                    n_jobs=-1)\n",
    "voting_classifer.fit(X_train, y_train)\n",
    "y_pred = voting_classifer.predict(x_test)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.20942\n",
      "Precision:\t0.21746255034331302\n",
      "Recall:\t0.20942\n",
      "F1:\t0.19530824327728674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1030, 2684, 3488, 2215,  583],\n",
       "       [ 950, 2696, 3513, 2222,  619],\n",
       "       [ 868, 2793, 3491, 2244,  604],\n",
       "       [ 853, 2554, 3457, 2460,  676],\n",
       "       [ 826, 2532, 3486, 2362,  794]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = [knn,lr,dt,rf]\n",
    "stacked = StackingClassifier(\n",
    "    classifiers=model_list, meta_classifier=LogisticRegression(n_jobs=-1), use_probas=False)\n",
    "stacked.fit(X_train, y_train)\n",
    "y_pred = stacked.predict(x_test)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_classifer.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15937302, 0.12098713, 0.17833713, 0.40606061, 0.13524211],\n",
       "       [0.1367587 , 0.15435234, 0.14926824, 0.38481209, 0.17480863],\n",
       "       [0.15269628, 0.14886068, 0.18828382, 0.12502046, 0.38513876],\n",
       "       ...,\n",
       "       [0.14162417, 0.39984444, 0.14350232, 0.18189237, 0.1331367 ],\n",
       "       [0.16447874, 0.20700267, 0.15188083, 0.12690068, 0.34973708],\n",
       "       [0.5871458 , 0.05535225, 0.25366229, 0.04987202, 0.05396765]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0e1bddb7ed37f67f576e4a6a21b2408ebab9a006050dc6d038d31036c144c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
