{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes\n",
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 57750)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "x = np.memmap('data_full/test_binary_data.npy',mode='r', shape = (50000,275*210))\n",
    "# x = np.load('data/gray_data_20')\n",
    "y = np.memmap('data/test_target.npy', mode='r', shape = (50000,))\n",
    "# x_test = np.memmap('data/test_gray_data_360.npy', mode='r', shape = (50000,360))\n",
    "# y_test = np.memmap('data/test_target.npy', mode='r', shape = (50000))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "# y = y == 2\n",
    "# y = y.astype(int)\n",
    "# y_test = y_test == 2\n",
    "# y_test = y_test.astype(int)\n",
    "# x = x/255\n",
    "# x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"target_data\": {\n",
    "\"Inco\": 2, \n",
    "\"Teac\": 1, \n",
    "\"Cons\": 0, \n",
    "\"Publ\": 4, \n",
    "\"Econ\": 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 57750)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(x, y[0], test_size=0.4, stratify=y)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 5000\n",
    "for i in range(X_train.shape[0]//chunk):\n",
    "    X_train[i*chunk:(i+1)*chunk] = X_train[i*chunk:(i+1)*chunk]/255\n",
    "for i in range(x_test.shape[0]//chunk):\n",
    "    x_test[i*chunk:(i+1)*chunk] = x_test[i*chunk:(i+1)*chunk]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57740</th>\n",
       "      <th>57741</th>\n",
       "      <th>57742</th>\n",
       "      <th>57743</th>\n",
       "      <th>57744</th>\n",
       "      <th>57745</th>\n",
       "      <th>57746</th>\n",
       "      <th>57747</th>\n",
       "      <th>57748</th>\n",
       "      <th>57749</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26053</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12773</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21327</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14943</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44221</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32765</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 57750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9      \\\n",
       "26053      1      1      1      1      1      1      1      1      1      1   \n",
       "12773      1      1      1      1      1      1      1      1      1      1   \n",
       "25194      1      1      1      1      0      0      0      1      1      1   \n",
       "21327      1      1      1      1      1      1      1      1      1      1   \n",
       "14943      1      1      1      1      1      1      1      0      0      0   \n",
       "9764       1      0      1      1      1      1      1      0      0      0   \n",
       "13974      1      1      1      1      1      1      1      1      1      1   \n",
       "44221      1      0      0      0      0      0      0      0      0      0   \n",
       "934        1      0      0      1      1      1      1      1      1      1   \n",
       "32765      1      0      1      0      0      1      1      0      0      0   \n",
       "\n",
       "       ...  57740  57741  57742  57743  57744  57745  57746  57747  57748  \\\n",
       "26053  ...      0      0      0      0      0      0      0      0      0   \n",
       "12773  ...      1      1      1      1      1      1      1      1      1   \n",
       "25194  ...      0      0      0      0      0      1      1      1      1   \n",
       "21327  ...      1      1      1      1      1      1      1      1      1   \n",
       "14943  ...      1      0      0      0      0      0      0      1      1   \n",
       "9764   ...      1      1      1      1      1      1      1      1      1   \n",
       "13974  ...      1      1      1      1      1      1      1      1      1   \n",
       "44221  ...      0      0      0      0      0      0      0      1      1   \n",
       "934    ...      1      0      0      1      1      1      1      1      1   \n",
       "32765  ...      0      1      1      1      0      0      1      0      1   \n",
       "\n",
       "       57749  \n",
       "26053      0  \n",
       "12773      1  \n",
       "25194      1  \n",
       "21327      1  \n",
       "14943      1  \n",
       "9764       1  \n",
       "13974      1  \n",
       "44221      1  \n",
       "934        1  \n",
       "32765      0  \n",
       "\n",
       "[10 rows x 57750 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Full\n",
    "~~~\n",
    "Accuracy:\t0.69805\n",
    "Precision:\t0.7095664115700494\n",
    "Recall:\t0.69805\n",
    "F1:\t0.6999680256379462\n",
    "array([[3381,  119,   80,   22,  398],\n",
    "       [  37, 2885,  538,  314,  226],\n",
    "       [  33,  308, 2610,  428,  621],\n",
    "       [  27,  460,  900, 2208,  405],\n",
    "       [ 175,  268,  576,  104, 2877]])\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.69805\n",
      "Precision:\t0.7095664115700494\n",
      "Recall:\t0.69805\n",
      "F1:\t0.6999680256379462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3381,  119,   80,   22,  398],\n",
       "       [  37, 2885,  538,  314,  226],\n",
       "       [  33,  308, 2610,  428,  621],\n",
       "       [  27,  460,  900, 2208,  405],\n",
       "       [ 175,  268,  576,  104, 2877]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "chunk = 5000\n",
    "for i in range(X_train.shape[0]//chunk):\n",
    "    nb.partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk], classes=[0,1,2,3,4])\n",
    "y_pred = nb.predict(x_test,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli OVR\n",
    "~~~\n",
    "Average F1:    0.76\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\t2\n",
      "\tAccuracy:\t0.7344\n",
      "\tPrecision:\t0.6613408482353865\n",
      "\tRecall:\t0.73115625\n",
      "\tF1:\t0.669147722415288\n",
      "[[11785  4215]\n",
      " [ 1097  2903]]\n",
      "Target:\t1\n",
      "\tAccuracy:\t0.84015\n",
      "\tPrecision:\t0.7533558167881398\n",
      "\tRecall:\t0.79575\n",
      "\tF1:\t0.7702984129333934\n",
      "[[13916  2084]\n",
      " [ 1113  2887]]\n",
      "Target:\t0\n",
      "\tAccuracy:\t0.9664\n",
      "\tPrecision:\t0.9480960806262011\n",
      "\tRecall:\t0.94675\n",
      "\tF1:\t0.9474210790396386\n",
      "[[15672   328]\n",
      " [  344  3656]]\n",
      "Target:\t4\n",
      "\tAccuracy:\t0.7716\n",
      "\tPrecision:\t0.6829287451850088\n",
      "\tRecall:\t0.7430625\n",
      "\tF1:\t0.6981058015975647\n",
      "[[12650  3350]\n",
      " [ 1218  2782]]\n",
      "Target:\t3\n",
      "\tAccuracy:\t0.77895\n",
      "\tPrecision:\t0.6781784847887601\n",
      "\tRecall:\t0.7185937499999999\n",
      "\tF1:\t0.6918055283124043\n",
      "[[13107  2893]\n",
      " [ 1528  2472]]\n"
     ]
    }
   ],
   "source": [
    "models={}\n",
    "mapping = {\"Inco\": 2, \n",
    "            \"Teac\": 1, \n",
    "            \"Cons\": 0, \n",
    "            \"Publ\": 4, \n",
    "            \"Econ\": 3}\n",
    "\n",
    "for key in mapping.keys():\n",
    "    target_class = mapping[key]\n",
    "    print(f'Target:\\t{target_class}')\n",
    "    models[key] =  BernoulliNB()\n",
    "    chunk = 1000\n",
    "    for i in range(X_train.shape[0]//chunk):\n",
    "        models[key].partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk]==target_class, classes=[0,1])\n",
    "        print(i,end='\\r', flush=True)\n",
    "    # y_pred = models[key].predict(x_test,)\n",
    "    y_pred = np.copy(y_test)\n",
    "    for i in range(x_test.shape[0]//chunk):\n",
    "        y_pred[i*chunk:(i+1)*chunk] = models[key].predict(x_test[i*chunk:(i+1)*chunk]/255)\n",
    "        print(i,end='\\r', flush=True)\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test==target_class, y_pred)}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test==target_class, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Full Tuning\n",
    "~~~\n",
    "Accuracy:\t0.69805\n",
    "Precision:\t0.7095664115700494\n",
    "Recall:\t0.69805\n",
    "F1:\t0.6999680256379462\n",
    "array([[3381,  119,   80,   22,  398],\n",
    "       [  37, 2885,  538,  314,  226],\n",
    "       [  33,  308, 2610,  428,  621],\n",
    "       [  27,  460,  900, 2208,  405],\n",
    "       [ 175,  268,  576,  104, 2877]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:\t1e-06\n",
      "\tAccuracy:\t0.6981\n",
      "\tPrecision:\t0.7097128562078444\n",
      "\tRecall:\t0.6980999999999999\n",
      "\tF1:\t0.7000347234774849\n",
      "[[3381  118   80   22  399]\n",
      " [  37 2885  539  313  226]\n",
      " [  32  307 2609  427  625]\n",
      " [  27  460  900 2208  405]\n",
      " [ 175  267  576  103 2879]]\n",
      "Alpha:\t1e-05\n",
      "\tAccuracy:\t0.6981\n",
      "\tPrecision:\t0.7097128562078444\n",
      "\tRecall:\t0.6980999999999999\n",
      "\tF1:\t0.7000347234774849\n",
      "[[3381  118   80   22  399]\n",
      " [  37 2885  539  313  226]\n",
      " [  32  307 2609  427  625]\n",
      " [  27  460  900 2208  405]\n",
      " [ 175  267  576  103 2879]]\n",
      "Alpha:\t0.0001\n",
      "\tAccuracy:\t0.6981\n",
      "\tPrecision:\t0.7097128562078444\n",
      "\tRecall:\t0.6980999999999999\n",
      "\tF1:\t0.7000347234774849\n",
      "[[3381  118   80   22  399]\n",
      " [  37 2885  539  313  226]\n",
      " [  32  307 2609  427  625]\n",
      " [  27  460  900 2208  405]\n",
      " [ 175  267  576  103 2879]]\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.6981\n",
      "\tPrecision:\t0.7097128562078444\n",
      "\tRecall:\t0.6980999999999999\n",
      "\tF1:\t0.7000347234774849\n",
      "[[3381  118   80   22  399]\n",
      " [  37 2885  539  313  226]\n",
      " [  32  307 2609  427  625]\n",
      " [  27  460  900 2208  405]\n",
      " [ 175  267  576  103 2879]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.69805\n",
      "\tPrecision:\t0.7096381939360124\n",
      "\tRecall:\t0.6980500000000001\n",
      "\tF1:\t0.6999819223367079\n",
      "[[3381  118   80   22  399]\n",
      " [  37 2885  538  314  226]\n",
      " [  32  307 2609  427  625]\n",
      " [  27  460  900 2208  405]\n",
      " [ 175  268  576  103 2878]]\n",
      "Alpha:\t10\n",
      "\tAccuracy:\t0.6979\n",
      "\tPrecision:\t0.7090949990560957\n",
      "\tRecall:\t0.6979\n",
      "\tF1:\t0.6998001551184773\n",
      "[[3381  119   80   22  398]\n",
      " [  36 2904  530  307  223]\n",
      " [  33  315 2601  436  615]\n",
      " [  27  471  892 2214  396]\n",
      " [ 175  278  582  107 2858]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.69465\n",
      "\tPrecision:\t0.7040817539471373\n",
      "\tRecall:\t0.69465\n",
      "\tF1:\t0.6960958788060564\n",
      "[[3369  143   80   26  382]\n",
      " [  30 3030  454  300  186]\n",
      " [  30  418 2542  487  523]\n",
      " [  24  595  826 2220  335]\n",
      " [ 157  373  608  130 2732]]\n",
      "Alpha:\t1000\n",
      "\tAccuracy:\t0.56095\n",
      "\tPrecision:\t0.6677089093936611\n",
      "\tRecall:\t0.5609499999999998\n",
      "\tF1:\t0.5619846920246936\n",
      "[[3009  578   50  105  258]\n",
      " [   3 3694   98  165   40]\n",
      " [   6 1810 1603  444  137]\n",
      " [   4 2086  222 1607   81]\n",
      " [  42 1895  462  295 1306]]\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.000001,0.00001,0.0001,0.001,0.1,10,100,1000]:\n",
    "    print(f'Alpha:\\t{alpha}')\n",
    "\n",
    "    nb = BernoulliNB(alpha=alpha)\n",
    "    chunk = 5000\n",
    "    for i in range(X_train.shape[0]//chunk):\n",
    "        nb.partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk], classes=[0,1,2,3,4])\n",
    "    y_pred = nb.predict(x_test,)\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli OVR Tuning\n",
    "~~~\n",
    "Accuracy:\t0.69805\n",
    "Precision:\t0.7095664115700494\n",
    "Recall:\t0.69805\n",
    "F1:\t0.6999680256379462\n",
    "array([[3381,  119,   80,   22,  398],\n",
    "       [  37, 2885,  538,  314,  226],\n",
    "       [  33,  308, 2610,  428,  621],\n",
    "       [  27,  460,  900, 2208,  405],\n",
    "       [ 175,  268,  576,  104, 2877]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:\tInco\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.7344\n",
      "\tPrecision:\t0.6612956987755488\n",
      "\tRecall:\t0.7310625\n",
      "\tF1:\t0.6691111083537036\n",
      "[[11786  4214]\n",
      " [ 1098  2902]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.73445\n",
      "\tPrecision:\t0.6613728057440168\n",
      "\tRecall:\t0.7311875\n",
      "\tF1:\t0.6691917048116421\n",
      "[[11786  4214]\n",
      " [ 1097  2903]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.7279\n",
      "\tPrecision:\t0.659376869799536\n",
      "\tRecall:\t0.73140625\n",
      "\tF1:\t0.6651122261729379\n",
      "[[11609  4391]\n",
      " [ 1051  2949]]\n",
      "Alpha:\t10000\n",
      "\tAccuracy:\t0.79985\n",
      "\tPrecision:\t0.5\n",
      "\tRecall:\t0.5\n",
      "\tF1:\t0.44464474275886917\n",
      "[[15996     4]\n",
      " [ 3999     1]]\n",
      "============================================================\n",
      "\n",
      "\n",
      "Model:\tTeac\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.84015\n",
      "\tPrecision:\t0.7533316710618694\n",
      "\tRecall:\t0.7955625\n",
      "\tF1:\t0.7702255682372188\n",
      "[[13918  2082]\n",
      " [ 1115  2885]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.84015\n",
      "\tPrecision:\t0.7533316710618694\n",
      "\tRecall:\t0.7955625\n",
      "\tF1:\t0.7702255682372188\n",
      "[[13918  2082]\n",
      " [ 1115  2885]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.8326\n",
      "\tPrecision:\t0.7467551620022036\n",
      "\tRecall:\t0.8036875\n",
      "\tF1:\t0.76707161882609\n",
      "[[13630  2370]\n",
      " [  978  3022]]\n",
      "Alpha:\t10000\n",
      "\tAccuracy:\t0.79975\n",
      "\tPrecision:\t0.3999749937484371\n",
      "\tRecall:\t0.49984375\n",
      "\tF1:\t0.4443672732323934\n",
      "[[15995     5]\n",
      " [ 4000     0]]\n",
      "============================================================\n",
      "\n",
      "\n",
      "Model:\tCons\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.96635\n",
      "\tPrecision:\t0.9482053971666586\n",
      "\tRecall:\t0.9464375\n",
      "\tF1:\t0.947318066690936\n",
      "[[15674   326]\n",
      " [  347  3653]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.96635\n",
      "\tPrecision:\t0.9482053971666586\n",
      "\tRecall:\t0.9464375\n",
      "\tF1:\t0.947318066690936\n",
      "[[15674   326]\n",
      " [  347  3653]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.96715\n",
      "\tPrecision:\t0.9452566539960441\n",
      "\tRecall:\t0.953125\n",
      "\tF1:\t0.949123202868615\n",
      "[[15624   376]\n",
      " [  281  3719]]\n",
      "Alpha:\t10000\n",
      "\tAccuracy:\t0.8003\n",
      "\tPrecision:\t0.9001200360108033\n",
      "\tRecall:\t0.50075\n",
      "\tF1:\t0.44601628423620054\n",
      "[[16000     0]\n",
      " [ 3994     6]]\n",
      "============================================================\n",
      "\n",
      "\n",
      "Model:\tPubl\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.7716\n",
      "\tPrecision:\t0.6829287451850088\n",
      "\tRecall:\t0.7430625\n",
      "\tF1:\t0.6981058015975647\n",
      "[[12650  3350]\n",
      " [ 1218  2782]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.77165\n",
      "\tPrecision:\t0.6829689108442174\n",
      "\tRecall:\t0.74309375\n",
      "\tF1:\t0.6981522040511987\n",
      "[[12651  3349]\n",
      " [ 1218  2782]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.7561\n",
      "\tPrecision:\t0.6719483580928018\n",
      "\tRecall:\t0.73553125\n",
      "\tF1:\t0.684804164524007\n",
      "[[12317  3683]\n",
      " [ 1195  2805]]\n",
      "Alpha:\t10000\n",
      "\tAccuracy:\t0.8\n",
      "\tPrecision:\t0.6500300060012003\n",
      "\tRecall:\t0.5001875\n",
      "\tF1:\t0.4449377714184915\n",
      "[[15998     2]\n",
      " [ 3998     2]]\n",
      "============================================================\n",
      "\n",
      "\n",
      "Model:\tEcon\n",
      "Alpha:\t0.001\n",
      "\tAccuracy:\t0.7791\n",
      "\tPrecision:\t0.678249493103004\n",
      "\tRecall:\t0.7185\n",
      "\tF1:\t0.6918546928458773\n",
      "[[13112  2888]\n",
      " [ 1530  2470]]\n",
      "Alpha:\t0.1\n",
      "\tAccuracy:\t0.7792\n",
      "\tPrecision:\t0.6783769598457836\n",
      "\tRecall:\t0.71865625\n",
      "\tF1:\t0.691994188231642\n",
      "[[13113  2887]\n",
      " [ 1529  2471]]\n",
      "Alpha:\t100\n",
      "\tAccuracy:\t0.7617\n",
      "\tPrecision:\t0.6678261872549078\n",
      "\tRecall:\t0.71934375\n",
      "\tF1:\t0.6813298443921461\n",
      "[[12639  3361]\n",
      " [ 1405  2595]]\n",
      "Alpha:\t10000\n",
      "\tAccuracy:\t0.79985\n",
      "\tPrecision:\t0.5\n",
      "\tRecall:\t0.5\n",
      "\tF1:\t0.44464474275886917\n",
      "[[15996     4]\n",
      " [ 3999     1]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "mapping = {\"Inco\": 2, \n",
    "            \"Teac\": 1, \n",
    "            \"Cons\": 0, \n",
    "            \"Publ\": 4, \n",
    "            \"Econ\": 3}\n",
    "\n",
    "for key in mapping.keys():\n",
    "    target_class = mapping[key]\n",
    "    print(f'\\n\\nModel:\\t{key}')\n",
    "    for alpha in [0.001,0.1,100,10000]:\n",
    "        print(f'Alpha:\\t{alpha}')\n",
    "        nb = BernoulliNB(alpha=alpha)\n",
    "        chunk = 1000\n",
    "        for i in range(X_train.shape[0]//chunk):\n",
    "            nb.partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk]==target_class, classes=[0,1])\n",
    "            print(i,end='\\r', flush=True)\n",
    "        # y_pred = models[key].predict(x_test,)\n",
    "        y_pred = np.copy(y_test)\n",
    "        for i in range(x_test.shape[0]//chunk):\n",
    "            y_pred[i*chunk:(i+1)*chunk] = nb.predict(x_test[i*chunk:(i+1)*chunk])\n",
    "            print(i,end='\\r', flush=True)\n",
    "        print(f'\\tAccuracy:\\t{accuracy_score(y_test==target_class, y_pred)}')\n",
    "        print(f'\\tPrecision:\\t{precision_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "        print(f'\\tRecall:\\t{recall_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "        print(f'\\tF1:\\t{f1_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "        print(confusion_matrix(y_test==target_class, y_pred))\n",
    "    print(\"===\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6559\n",
      "\tPrecision:\t0.6338589811593689\n",
      "\tRecall:\t0.5465833333333333\n",
      "\tF1:\t0.5818054425234621\n",
      "[[3604   81   23    6  170  116]\n",
      " [  44 2805  379  176  103  493]\n",
      " [  36  233 2434  255  402  640]\n",
      " [  34  420  662 1869  248  767]\n",
      " [ 195  214  491   25 2406  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "============================================================\n",
      "\n",
      "\n",
      "Data Size:\t17315/20000\n",
      "\tAccuracy:\t0.7576090095293099\n",
      "\tPrecision:\t0.7606307773912426\n",
      "\tRecall:\t0.7505098992710385\n",
      "\tF1:\t0.750785960714724\n",
      "[[3604   81   23    6  170]\n",
      " [  44 2805  379  176  103]\n",
      " [  36  233 2434  255  402]\n",
      " [  34  420  662 1869  248]\n",
      " [ 195  214  491   25 2406]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mapping = {\"Inco\": 2, \n",
    "            \"Teac\": 1, \n",
    "            \"Cons\": 0, \n",
    "            \"Publ\": 4, \n",
    "            \"Econ\": 3}\n",
    "x=0\n",
    "results = np.zeros((y_test.shape[0],5))\n",
    "for key in mapping.keys():\n",
    "    y_pred = np.zeros(shape=y_test.shape)\n",
    "    for i in range(x_test.shape[0]//chunk):\n",
    "        y_pred[i*chunk:(i+1)*chunk] = models[key].predict_proba(x_test[i*chunk:(i+1)*chunk]/255)[:,0]\n",
    "        print(i,end='\\r', flush=True)\n",
    "    results[:,mapping[key]] = y_pred\n",
    "    x+=1\n",
    "test = np.copy(y_test)\n",
    "for  i in range(results[:,0].shape[0]):\n",
    "    max = np.where(results[i,:] == np.amin(results[i,:].reshape(5)))[0]\n",
    "    if len(max)>1:\n",
    "        test[i] = 5\n",
    "    else:\n",
    "        test[i]=max[0]\n",
    "y_pred = test\n",
    "mask = y_pred != 5\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"===\"*20)\n",
    "\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred[mask])}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test[mask], y_pred[mask])}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(confusion_matrix(y_test[mask], y_pred[mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup up for Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Done Training!!\n"
     ]
    }
   ],
   "source": [
    "models={}\n",
    "mapping = {\"Inco\": 2, \n",
    "            \"Teac\": 1, \n",
    "            \"Cons\": 0, \n",
    "            \"Publ\": 4, \n",
    "            \"Econ\": 3}\n",
    "\n",
    "nb_full = BernoulliNB(alpha=10)\n",
    "for key in mapping.keys():\n",
    "    models[key] =  BernoulliNB(alpha=0.1)\n",
    "\n",
    "chunk = 5000\n",
    "\n",
    "for i in range(X_train.shape[0]//chunk):\n",
    "    nb_full.partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk], classes=[0,1,2,3,4])\n",
    "    for key in mapping.keys():\n",
    "        target_class = mapping[key]\n",
    "        models[key].partial_fit(X_train[i*chunk:(i+1)*chunk], y_train[i*chunk:(i+1)*chunk]==target_class, classes=[0,1])\n",
    "    print(i,end='\\r', flush=True)\n",
    "print('\\nDone Training!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base OVR Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6528\n",
      "\tPrecision:\t0.6346833410323662\n",
      "\tRecall:\t0.544\n",
      "\tF1:\t0.5797365169480789\n",
      "[[3596   86   25    4  170  119]\n",
      " [  41 2810  412  168  106  463]\n",
      " [  43  208 2468  223  367  691]\n",
      " [  30  398  724 1868  215  765]\n",
      " [ 216  216  551   25 2314  678]\n",
      " [   0    0    0    0    0    0]]\n",
      "============================================================\n",
      "Filtered OVR Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17284/20000\n",
      "\tAccuracy:\t0.7553806989122889\n",
      "\tPrecision:\t0.7616200092388394\n",
      "\tRecall:\t0.7481742419074908\n",
      "\tF1:\t0.7488129071230087\n",
      "[[3596   86   25    4  170]\n",
      " [  41 2810  412  168  106]\n",
      " [  43  208 2468  223  367]\n",
      " [  30  398  724 1868  215]\n",
      " [ 216  216  551   25 2314]]\n",
      "============================================================\n",
      "Base Multiclass\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.70135\n",
      "\tPrecision:\t0.7111246445305771\n",
      "\tRecall:\t0.70135\n",
      "\tF1:\t0.703020508896214\n",
      "[[3459  111   71   34  325]\n",
      " [  44 2887  538  348  183]\n",
      " [  38  266 2706  431  559]\n",
      " [  35  479  920 2227  339]\n",
      " [ 186  278  668  120 2748]]\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "============================================================\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = np.zeros((y_test.shape[0],5))\n",
    "nb_full_results = np.zeros((y_test.shape[0],5))\n",
    "    # y_pred = np.zeros(shape=y_test.shape)\n",
    "for i in range(x_test.shape[0]//chunk):\n",
    "    y_pred = nb_full.predict_proba(x_test[i*chunk:(i+1)*chunk])[:]\n",
    "    nb_full_results[i*chunk:(i+1)*chunk] = y_pred\n",
    "    for key in mapping.keys():\n",
    "        y_pred = models[key].predict_proba(x_test[i*chunk:(i+1)*chunk])[:,0]\n",
    "        results[i*chunk:(i+1)*chunk,mapping[key]] = y_pred\n",
    "    print(i,end='\\r', flush=True)\n",
    "    # results[:,mapping[key]] = y_pred\n",
    "test = np.copy(y_test)\n",
    "test2 = np.copy(y_test)\n",
    "test3 = np.copy(y_test)\n",
    "\n",
    "added_results = np.zeros(nb_full_results.shape)\n",
    "full_results = np.zeros(shape=y_test.shape)\n",
    "\n",
    "fixed_ordering = [2,1,0,4,3]\n",
    "for  i in range(results[:,0].shape[0]):\n",
    "    added_results[i,:] = results[i,:] + (np.absolute(nb_full_results[i,:]-1)/1.0e+200)\n",
    "    max = np.where(results[i,:] == np.amin(results[i,:].reshape(5)))[0]\n",
    "    max2 = np.where(added_results[i,:] == np.amin(added_results[i,:].reshape(5)))[0]\n",
    "    max3 = np.where(nb_full_results[i,:]== np.amax(nb_full_results[i,:].reshape(5)))[0]\n",
    "    # max4 = np.amin(nb_full_results[i,:].reshape(5))\n",
    "    if len(max)>1:\n",
    "        test[i] = 5\n",
    "    else:\n",
    "        test[i]=max[0]\n",
    "\n",
    "    if len(max2)>1:\n",
    "        test2[i] = 5\n",
    "    else:\n",
    "        test2[i]=max2[0]\n",
    "\n",
    "    if len(max3)>1:\n",
    "        test3[i] = 5\n",
    "    else:\n",
    "        test3[i]=max3[0]\n",
    "y_pred = test\n",
    "mask = y_pred != 5\n",
    "\n",
    "print('Base OVR Ensemble')\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"===\"*20)\n",
    "\n",
    "print('Filtered OVR Ensemble')\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred[mask])}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test[mask], y_pred[mask])}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(confusion_matrix(y_test[mask], y_pred[mask]))\n",
    "\n",
    "print(\"===\"*20)\n",
    "\n",
    "y_pred = test3\n",
    "print('Base Multiclass')\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"===\"*20)\n",
    "\n",
    "y_pred = test2\n",
    "mask = y_pred != 5\n",
    "print('Base Multiclass Ensemble')\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"===\"*20)\n",
    "\n",
    "print('Filtered Multiclass Ensemble')\n",
    "print(f'\\n\\nData Size:\\t{len(y_pred[mask])}/{len(y_pred)}')\n",
    "print(f'\\tAccuracy:\\t{accuracy_score(y_test[mask], y_pred[mask])}')\n",
    "print(f'\\tPrecision:\\t{precision_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tRecall:\\t{recall_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(f'\\tF1:\\t{f1_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "print(confusion_matrix(y_test[mask], y_pred[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1e+20\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6545\n",
      "\tPrecision:\t0.6314140819605494\n",
      "\tRecall:\t0.5454166666666665\n",
      "\tF1:\t0.580773815856841\n",
      "[[3523   95   25    7  233  117]\n",
      " [  39 2801  403  187  110  460]\n",
      " [  42  211 2440  243  388  676]\n",
      " [  30  397  701 1966  222  684]\n",
      " [ 203  210  529   29 2360  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7525583534552145\n",
      "\tPrecision:\t0.7576968983526593\n",
      "\tRecall:\t0.7467930821618101\n",
      "\tF1:\t0.747388405922832\n",
      "[[3523   95   25    7  233]\n",
      " [  39 2801  403  187  110]\n",
      " [  42  211 2440  243  388]\n",
      " [  30  397  701 1966  222]\n",
      " [ 203  210  529   29 2360]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1.1e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2.2e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3.3e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4.4e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5.5e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6.6e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7.7e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "8.8e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "9.9e+200\n",
      "============================================================\n",
      "Base Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t20000/20000\n",
      "\tAccuracy:\t0.6566\n",
      "\tPrecision:\t0.634421639835416\n",
      "\tRecall:\t0.5471666666666667\n",
      "\tF1:\t0.5819790229606387\n",
      "[[3594   88   26    4  171  117]\n",
      " [  40 2811  415  168  106  460]\n",
      " [  43  216 2467  225  373  676]\n",
      " [  30  413  718 1937  218  684]\n",
      " [ 216  218  549   25 2323  669]\n",
      " [   0    0    0    0    0    0]]\n",
      "Filtered Multiclass Ensemble\n",
      "\n",
      "\n",
      "Data Size:\t17394/20000\n",
      "\tAccuracy:\t0.7549729791882258\n",
      "\tPrecision:\t0.7613059678024993\n",
      "\tRecall:\t0.7486689185287843\n",
      "\tF1:\t0.7490805336150097\n",
      "[[3594   88   26    4  171]\n",
      " [  40 2811  415  168  106]\n",
      " [  43  216 2467  225  373]\n",
      " [  30  413  718 1937  218]\n",
      " [ 216  218  549   25 2323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for x in np.linspace(1.0e+20,9.9e+200, 10):\n",
    "    test = np.copy(y_test)\n",
    "    test2 = np.copy(y_test)\n",
    "    test3 = np.copy(y_test)\n",
    "\n",
    "    added_results = np.zeros(nb_full_results.shape)\n",
    "    full_results = np.zeros(shape=y_test.shape)\n",
    "\n",
    "    fixed_ordering = [2,1,0,4,3]\n",
    "    for  i in range(results[:,0].shape[0]):\n",
    "        added_results[i,:] = results[i,:] + (np.absolute(nb_full_results[i,:]-1)/x)\n",
    "        max = np.where(results[i,:] == np.amin(results[i,:].reshape(5)))[0]\n",
    "        max2 = np.where(added_results[i,:] == np.amin(added_results[i,:].reshape(5)))[0]\n",
    "        max3 = np.where(nb_full_results[i,:]== np.amax(nb_full_results[i,:].reshape(5)))[0]\n",
    "        # max4 = np.amin(nb_full_results[i,:].reshape(5))\n",
    "        if len(max)>1:\n",
    "            test[i] = 5\n",
    "        else:\n",
    "            test[i]=max[0]\n",
    "\n",
    "        if len(max2)>1:\n",
    "            test2[i] = 5\n",
    "        else:\n",
    "            test2[i]=max2[0]\n",
    "\n",
    "        if len(max3)>1:\n",
    "            test3[i] = 5\n",
    "        else:\n",
    "            test3[i]=max3[0]\n",
    "    y_pred = test\n",
    "    mask = y_pred != 5\n",
    "\n",
    "    print(\"===\"*20)\n",
    "    print(x)\n",
    "    print(\"===\"*20)\n",
    "\n",
    "    y_pred = test2\n",
    "    mask = y_pred != 5\n",
    "    print('Base Multiclass Ensemble')\n",
    "    print(f'\\n\\nData Size:\\t{len(y_pred)}/{len(y_pred)}')\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "    print('Filtered Multiclass Ensemble')\n",
    "    print(f'\\n\\nData Size:\\t{len(y_pred[mask])}/{len(y_pred)}')\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test[mask], y_pred[mask])}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test[mask], y_pred[mask], average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test[mask], y_pred[mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gaussian Naive Bayes\n",
    "##### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 57750)\n",
      "(50000,)\n",
      "(30000, 57750)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "x = np.memmap('data_full/test_gray_data.npy',mode='r', shape = (50000,275*210))\n",
    "y = np.memmap('data/test_target.npy', mode='r', shape = (50000,))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "X_train, x_test, y_train, y_test = train_test_split(x, y[0], test_size=0.4, stratify=y)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57740</th>\n",
       "      <th>57741</th>\n",
       "      <th>57742</th>\n",
       "      <th>57743</th>\n",
       "      <th>57744</th>\n",
       "      <th>57745</th>\n",
       "      <th>57746</th>\n",
       "      <th>57747</th>\n",
       "      <th>57748</th>\n",
       "      <th>57749</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.435294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.556863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.925490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 57750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6      \\\n",
       "49990  0.482353  0.737255  0.917647  0.760784  0.827451  0.898039  0.694118   \n",
       "49991  0.992157  0.992157  0.992157  0.992157  0.992157  0.992157  0.992157   \n",
       "49992  0.988235  0.992157  0.992157  0.988235  0.980392  0.988235  0.988235   \n",
       "49993  0.603922  0.545098  0.658824  0.654902  0.603922  0.576471  0.619608   \n",
       "49994  0.113725  0.113725  0.113725  0.113725  0.113725  0.113725  0.113725   \n",
       "49995  1.000000  1.000000  1.000000  1.000000  1.000000  0.996078  0.996078   \n",
       "49996  0.180392  0.180392  0.180392  0.180392  1.000000  1.000000  1.000000   \n",
       "49997  0.713725  0.200000  0.000000  0.003922  0.015686  0.015686  0.015686   \n",
       "49998  0.113725  0.113725  0.113725  0.113725  0.113725  0.113725  0.113725   \n",
       "49999  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "          7         8         9      ...     57740     57741     57742  \\\n",
       "49990  0.686275  0.854902  0.356863  ...  0.470588  0.686275  0.764706   \n",
       "49991  0.992157  0.992157  0.992157  ...  0.992157  0.992157  0.992157   \n",
       "49992  1.000000  0.996078  0.988235  ...  0.992157  0.984314  0.988235   \n",
       "49993  0.564706  0.411765  0.400000  ...  0.580392  0.611765  0.580392   \n",
       "49994  0.070588  0.007843  0.501961  ...  1.000000  1.000000  1.000000   \n",
       "49995  0.996078  1.000000  0.996078  ...  1.000000  1.000000  1.000000   \n",
       "49996  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "49997  0.015686  0.015686  0.015686  ...  1.000000  1.000000  1.000000   \n",
       "49998  0.113725  0.113725  0.121569  ...  0.862745  0.729412  0.603922   \n",
       "49999  1.000000  1.000000  1.000000  ...  1.000000  1.000000  1.000000   \n",
       "\n",
       "          57743     57744     57745     57746     57747     57748     57749  \n",
       "49990  0.713725  0.203922  0.203922  0.270588  0.427451  0.435294  0.435294  \n",
       "49991  0.992157  0.992157  0.992157  0.992157  0.992157  0.992157  0.992157  \n",
       "49992  0.996078  0.996078  0.992157  0.992157  0.984314  0.996078  0.996078  \n",
       "49993  0.690196  0.592157  0.482353  0.509804  0.556863  0.549020  0.556863  \n",
       "49994  1.000000  1.000000  1.000000  1.000000  1.000000  0.976471  0.925490  \n",
       "49995  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
       "49996  1.000000  1.000000  1.000000  0.180392  0.180392  0.180392  0.180392  \n",
       "49997  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
       "49998  0.725490  0.858824  0.929412  0.992157  1.000000  1.000000  1.000000  \n",
       "49999  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
       "\n",
       "[10 rows x 57750 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-10:]/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Full\n",
    "~~~\n",
    "Accuracy:\t0.69805\n",
    "Precision:\t0.7095664115700494\n",
    "Recall:\t0.69805\n",
    "F1:\t0.6999680256379462\n",
    "array([[3381,  119,   80,   22,  398],\n",
    "       [  37, 2885,  538,  314,  226],\n",
    "       [  33,  308, 2610,  428,  621],\n",
    "       [  27,  460,  900, 2208,  405],\n",
    "       [ 175,  268,  576,  104, 2877]])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.61035\n",
      "Precision:\t0.6294562592896533\n",
      "Recall:\t0.6103500000000001\n",
      "F1:\t0.6026985327945201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3910,   78,    4,    1,    7],\n",
       "       [ 139, 2804,  475,  315,  267],\n",
       "       [ 172, 1007, 2131,  371,  319],\n",
       "       [ 152, 1448,  549, 1613,  238],\n",
       "       [ 260, 1098,  608,  285, 1749]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "chunk = 1000\n",
    "for i in range(X_train.shape[0]//chunk):\n",
    "    nb.partial_fit(X_train[i*chunk:(i+1)*chunk]/255, y_train[i*chunk:(i+1)*chunk], classes=[0,1,2,3,4])\n",
    "    print(i,end='\\r', flush=True)\n",
    "y_pred = np.copy(y_test)\n",
    "for i in range(x_test.shape[0]//chunk):\n",
    "    y_pred[i*chunk:(i+1)*chunk] = nb.predict(x_test[i*chunk:(i+1)*chunk]/255)\n",
    "    print(i,end='\\r', flush=True)\n",
    "# y_pred = nb.predict(x_test/255,)\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\t0\n",
      "\tAccuracy:\t0.94865\n",
      "\tPrecision:\t0.9003113496432245\n",
      "\tRecall:\t0.95965625\n",
      "\tF1:\t0.9254986761887338\n",
      "[[15061   939]\n",
      " [   88  3912]]\n",
      "Target:\t1\n",
      "\tAccuracy:\t0.5223\n",
      "\tPrecision:\t0.590013189508257\n",
      "\tRecall:\t0.6343125\n",
      "\tF1:\t0.5036381804337869\n",
      "[[7162 8838]\n",
      " [ 716 3284]]\n",
      "Target:\t2\n",
      "\tAccuracy:\t0.4636\n",
      "\tPrecision:\t0.578500296759402\n",
      "\tRecall:\t0.6075625\n",
      "\tF1:\t0.4551409764824462\n",
      "[[ 5882 10118]\n",
      " [  610  3390]]\n",
      "Target:\t3\n",
      "\tAccuracy:\t0.492\n",
      "\tPrecision:\t0.5866364622606982\n",
      "\tRecall:\t0.62390625\n",
      "\tF1:\t0.47957738200275113\n",
      "[[6465 9535]\n",
      " [ 625 3375]]\n",
      "Target:\t4\n",
      "\tAccuracy:\t0.45325\n",
      "\tPrecision:\t0.5618144743458695\n",
      "\tRecall:\t0.5855312500000001\n",
      "\tF1:\t0.443725624508982\n",
      "[[ 5841 10159]\n",
      " [  776  3224]]\n"
     ]
    }
   ],
   "source": [
    "for target_class in [0,1,2,3,4]:\n",
    "    print(f'Target:\\t{target_class}')\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    chunk = 1000\n",
    "    for i in range(X_train.shape[0]//chunk):\n",
    "        nb.partial_fit(X_train[i*chunk:(i+1)*chunk]/255, y_train[i*chunk:(i+1)*chunk]==target_class, classes=[0,1])\n",
    "        print(i,end='\\r', flush=True)\n",
    "    y_pred = np.copy(y_test)\n",
    "    for i in range(x_test.shape[0]//chunk):\n",
    "        y_pred[i*chunk:(i+1)*chunk] = nb.predict(x_test[i*chunk:(i+1)*chunk]/255)\n",
    "        print(i,end='\\r', flush=True)\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test==target_class, y_pred)}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test==target_class, y_pred, average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test==target_class, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var Smoothing:\t1e-06\n",
      "\tAccuracy:\t0.61035\n",
      "\tPrecision:\t0.6294562592896533\n",
      "\tRecall:\t0.6103500000000001\n",
      "\tF1:\t0.6026985327945201\n",
      "[[3910   78    4    1    7]\n",
      " [ 139 2804  475  315  267]\n",
      " [ 172 1007 2131  371  319]\n",
      " [ 152 1448  549 1613  238]\n",
      " [ 260 1098  608  285 1749]]\n",
      "Var Smoothing:\t1e-05\n",
      "\tAccuracy:\t0.61035\n",
      "\tPrecision:\t0.6294562592896533\n",
      "\tRecall:\t0.6103500000000001\n",
      "\tF1:\t0.6026985327945201\n",
      "[[3910   78    4    1    7]\n",
      " [ 139 2804  475  315  267]\n",
      " [ 172 1007 2131  371  319]\n",
      " [ 152 1448  549 1613  238]\n",
      " [ 260 1098  608  285 1749]]\n",
      "Var Smoothing:\t0.0001\n",
      "\tAccuracy:\t0.61035\n",
      "\tPrecision:\t0.6294562592896533\n",
      "\tRecall:\t0.6103500000000001\n",
      "\tF1:\t0.6026985327945201\n",
      "[[3910   78    4    1    7]\n",
      " [ 139 2804  475  315  267]\n",
      " [ 172 1007 2131  371  319]\n",
      " [ 152 1448  549 1613  238]\n",
      " [ 260 1098  608  285 1749]]\n",
      "Var Smoothing:\t0.001\n",
      "\tAccuracy:\t0.60985\n",
      "\tPrecision:\t0.6291360547988962\n",
      "\tRecall:\t0.60985\n",
      "\tF1:\t0.6021812589528474\n",
      "[[3910   78    4    1    7]\n",
      " [ 136 2805  477  317  265]\n",
      " [ 171 1010 2131  369  319]\n",
      " [ 152 1452  549 1610  237]\n",
      " [ 258 1103  610  288 1741]]\n",
      "Var Smoothing:\t0.1\n",
      "\tAccuracy:\t0.57855\n",
      "\tPrecision:\t0.616320983188755\n",
      "\tRecall:\t0.5785499999999999\n",
      "\tF1:\t0.5702742929106156\n",
      "[[3892   84    4    6   14]\n",
      " [  65 2892  504  343  196]\n",
      " [  88 1274 2035  379  224]\n",
      " [  80 1757  562 1427  174]\n",
      " [ 139 1457  674  405 1325]]\n",
      "Var Smoothing:\t0.2\n",
      "\tAccuracy:\t0.55595\n",
      "\tPrecision:\t0.6046905012586182\n",
      "\tRecall:\t0.5559499999999999\n",
      "\tF1:\t0.5461360536497307\n",
      "[[3873   90    4    7   26]\n",
      " [  39 2950  506  340  165]\n",
      " [  53 1447 1922  383  195]\n",
      " [  51 2015  560 1216  158]\n",
      " [  78 1644  705  415 1158]]\n",
      "Var Smoothing:\t0.4\n",
      "\tAccuracy:\t0.5287\n",
      "\tPrecision:\t0.5877464463767472\n",
      "\tRecall:\t0.5287\n",
      "\tF1:\t0.516734191561355\n",
      "[[3794  107   12   18   69]\n",
      " [  15 2995  516  337  137]\n",
      " [  22 1651 1792  372  163]\n",
      " [  22 2245  580 1031  122]\n",
      " [  35 1819  748  436  962]]\n",
      "Var Smoothing:\t0.6\n",
      "\tAccuracy:\t0.5119\n",
      "\tPrecision:\t0.5740137462148764\n",
      "\tRecall:\t0.5119\n",
      "\tF1:\t0.499286809766022\n",
      "[[3678  125   31   40  126]\n",
      " [   9 3010  520  340  121]\n",
      " [  12 1741 1729  374  144]\n",
      " [  10 2328  593  960  109]\n",
      " [  21 1912  771  435  861]]\n",
      "Var Smoothing:\t0.8\n",
      "\tAccuracy:\t0.4975\n",
      "\tPrecision:\t0.561265334265047\n",
      "\tRecall:\t0.49750000000000005\n",
      "\tF1:\t0.4847233646443293\n",
      "[[3542  145   70   71  172]\n",
      " [   7 3019  520  342  112]\n",
      " [  10 1790 1688  383  129]\n",
      " [   3 2380  613  906   98]\n",
      " [  15 1972  777  441  795]]\n"
     ]
    }
   ],
   "source": [
    "for smoothing in [0.000001,0.00001,0.0001,0.001,0.1,0.2,0.4,0.6,0.8]:\n",
    "    print(f'Var Smoothing:\\t{smoothing}')\n",
    "\n",
    "    nb = GaussianNB(var_smoothing=smoothing)\n",
    "    chunk = 1000\n",
    "    for i in range(X_train.shape[0]//chunk):\n",
    "        nb.partial_fit(X_train[i*chunk:(i+1)*chunk]/255, y_train[i*chunk:(i+1)*chunk], classes=[0,1,2,3,4])\n",
    "        print(i,end='\\r', flush=True)\n",
    "    y_pred = np.copy(y_test)\n",
    "    for i in range(x_test.shape[0]//chunk):\n",
    "        y_pred[i*chunk:(i+1)*chunk] = nb.predict(x_test[i*chunk:(i+1)*chunk]/255)\n",
    "        print(i,end='\\r', flush=True)\n",
    "    print(f'\\tAccuracy:\\t{accuracy_score(y_test, y_pred)}')\n",
    "    print(f'\\tPrecision:\\t{precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tRecall:\\t{recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(f'\\tF1:\\t{f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2887500000,)\n",
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "x = np.memmap('data_full/image_data_binary.npy',mode='r', shape = (150000,275*210))\n",
    "# x = np.load('data/gray_data_20')\n",
    "y = np.memmap('data/image_target.npy', mode='r', shape = (150000,))\n",
    "# x_test = np.memmap('data/test_gray_data_360.npy', mode='r', shape = (50000,360))\n",
    "# y_test = np.memmap('data/test_target.npy', mode='r', shape = (50000))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "# y = y == 2\n",
    "# y = y.astype(int)\n",
    "# y_test = y_test == 2\n",
    "# y_test = y_test.astype(int)\n",
    "# x = x/255\n",
    "# x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = arr.shape[0] # how many rows we have in the dataset\n",
    "chunk_size = 5000 # how many rows we feed to IPCA at a time, the divisor of n\n",
    "indices = np.arange(n)\n",
    "np.random.shuffle(indices)\n",
    "performance_test = {}\n",
    "\n",
    "for i in range(0, n//chunk_size):\n",
    "    pca = IncrementalPCA(n_components=20)\n",
    "    pca.partial_fit(arr[indices[i*chunk_size : (i+1)*chunk_size]])\n",
    "    print(f'{i}\\t/\\t {n//chunk_size}',end='\\r',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_classifer2.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision and Recall Curves')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_test, y_pred[:,1] )\n",
    "\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold (above this probability, label as fraud)')\n",
    "plt.title('Precision and Recall Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.69186\n",
      "Precision:\t0.5224424924588862\n",
      "Recall:\t0.522825\n",
      "F1:\t0.5226151458480693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32182,  7818],\n",
       "       [ 7589,  2411]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = y_pred[:,1]>0.3\n",
    "\n",
    "print(f'Accuracy:\\t{accuracy_score(y_test, y_pred2)}')\n",
    "print(f'Precision:\\t{precision_score(y_test, y_pred2, average=\"macro\")}')\n",
    "print(f'Recall:\\t{recall_score(y_test, y_pred2, average=\"macro\")}')\n",
    "print(f'F1:\\t{f1_score(y_test, y_pred2, average=\"macro\")}')\n",
    "confusion_matrix(y_test, y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0e1bddb7ed37f67f576e4a6a21b2408ebab9a006050dc6d038d31036c144c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
