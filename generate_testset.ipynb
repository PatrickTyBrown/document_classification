{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import string\n",
    "import random\n",
    "import albumentations as A\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_directory = 'templates_img'\n",
    "\n",
    "text_locations = json.load(open('text_locations.json', 'r'))\n",
    "\n",
    "image_dir =  \"data/\"\n",
    "\n",
    "backgrounds_dir = 'image_backgrounds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YN@V;xfSt%62]q'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_field(length = 0):\n",
    "    length = length if length else random.randint(2, 20)\n",
    "    field = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=length))\n",
    "    return field\n",
    "\n",
    "generate_random_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "        # A.RandomRotate90(),\n",
    "        # A.Flip(),\n",
    "        # A.Transpose(),\n",
    "        A.ImageCompression(quality_lower=10, p=0.1),\n",
    "        A.OneOf([\n",
    "            # A.IAAAdditiveGaussianNoise(),\n",
    "            A.GaussNoise(p=0.8),\n",
    "            A.ISONoise(p=0.2),\n",
    "            A.MultiplicativeNoise(p=.05)\n",
    "        ], p=0.1),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.05),\n",
    "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.2, rotate_limit=60, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.5),\n",
    "            A.GridDistortion(p=.5),\n",
    "            A.PiecewiseAffine(p=0.5),\n",
    "        ], p=0.5),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.Sharpen(),\n",
    "            A.Emboss(),\n",
    "            A.RandomBrightnessContrast(),            \n",
    "        ], p=0.05),\n",
    "        A.OneOf([\n",
    "            A.RandomFog(),\n",
    "            A.RandomRain(),\n",
    "            A.RandomSnow(),\n",
    "            A.RandomSunFlare(),            \n",
    "        ], p=0.1),\n",
    "        A.HueSaturationValue(p=0.01),\n",
    "        # A.Rotate(66,p=0.3)\n",
    "        # A.ToGray(always_apply=True)\n",
    "    ])\n",
    "# random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = [\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    cv2.FONT_HERSHEY_COMPLEX,\n",
    "    cv2.FONT_HERSHEY_PLAIN,\n",
    "    cv2.FONT_HERSHEY_DUPLEX,\n",
    "    cv2.FONT_HERSHEY_TRIPLEX,\n",
    "    cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "    cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "    cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "    cv2.FONT_ITALIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\r"
     ]
    }
   ],
   "source": [
    "def generate_target_dictionary():\n",
    "    with open('data_dictionary.json') as data_dict:\n",
    "        categories = json.load(data_dict)['target_data']\n",
    "    return categories\n",
    "categories = generate_target_dictionary()\n",
    "\n",
    "\n",
    "backgrounds = []\n",
    "for filename in os.listdir(backgrounds_dir):\n",
    "    img = cv2.imread(backgrounds_dir+ '/'+filename, 1)\n",
    "    backgrounds.append(img)\n",
    "\n",
    "test_gray = np.memmap('data_full/test_gray_data.npy', mode='w+', shape = (50000,275,210))\n",
    "test_binary = np.memmap('data_full/test_binary_data.npy', mode='w+', shape = (50000,275,210))\n",
    "test_target = np.memmap('data/test_target.npy', mode='w+', shape = (50000))\n",
    "\n",
    "index = 0\n",
    "for filename in text_locations:\n",
    "    if text_locations[filename] != {}:\n",
    "        image = cv2.imread(template_directory+ '/'+filename, 1)\n",
    "        image = cv2.resize(image, (850, 1100)) \n",
    "\n",
    "        doc_info = text_locations[filename]\n",
    "        for i in range(10000):\n",
    "            background_img = backgrounds[random.randint(0, len(backgrounds))-1]\n",
    "            img = image\n",
    "            for loc in doc_info:\n",
    "                font = random.choice(fonts)\n",
    "                cv2.putText(img, generate_random_field(),\n",
    "                            (int(loc['x']),int(loc['y'])), font,\n",
    "                            0.75, (255, 0, 0), 2)\n",
    "            # resize(210,275)\n",
    "            x_size = random.randint(-200,400)\n",
    "            y_size = random.randint(-200,400)\n",
    "            x_size = x_size if x_size > 0 else 0\n",
    "            y_size = y_size if y_size > 0 else 0\n",
    "            x_offset = int(x_size/2)\n",
    "            y_offset = int(y_size/2)\n",
    "            background_img = cv2.resize(background_img, (850+x_size, 1100+y_size)) \n",
    "\n",
    "            background_img[y_offset:y_offset+img.shape[0], x_offset:x_offset+img.shape[1]] = img\n",
    "            transformed = transform(image=cv2.resize(background_img, (210,275)))\n",
    "            img = transformed['image']\n",
    "            \n",
    "            img = cv2.cvtColor(transformed['image'], cv2.COLOR_BGR2GRAY)\n",
    "            test_gray[index] = img\n",
    "            # print(img.shape)\n",
    "            img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "            test_binary[index] = img\n",
    "            test_target[index] = categories[filename[:4]]\n",
    "\n",
    "            index+=1\n",
    "            # print(img.shape)\n",
    "            # cv2.imshow('image', img)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            print(index,end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/classification/lib/python3.10/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator IncrementalPCA from version 1.0.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray Model 0 done\n",
      "Gray Model 1 done\n",
      "Gray Model 2 done\n",
      "Gray Model 0 done\n",
      "Gray Model 1 done\n",
      "Gray Model 2 done\n"
     ]
    }
   ],
   "source": [
    "test_gray = np.memmap('data_full/test_gray_data.npy', mode='r', shape = (50000,275*210))\n",
    "test_binary = np.memmap('data_full/test_binary_data.npy', mode='r', shape = (50000,275*210))\n",
    "\n",
    "test_gray_20 = np.memmap('data/test_gray_data_20', mode='w+', shape = (50000,20))\n",
    "test_gray_120 = np.memmap('data/test_gray_data_120.npy', mode='w+', shape = (50000,120))\n",
    "test_gray_360 = np.memmap('data/test_gray_data_360.npy', mode='w+', shape = (50000,360))\n",
    "test_binary_20 = np.memmap('data/test_binary_data_20.npy', mode='w+', shape = (50000,20))\n",
    "test_binary_120 = np.memmap('data/test_binary_data_120.npy', mode='w+', shape = (50000,120))\n",
    "test_binary_360 = np.memmap('data/test_binary_data_360.npy', mode='w+', shape = (50000,360))\n",
    "gray_data = [test_gray_20,test_gray_120,test_gray_360]\n",
    "binary_data = [test_binary_20,test_binary_120,test_binary_360]\n",
    "\n",
    "gray_models =[]\n",
    "for x in [20,120,360]:\n",
    "    with open(f'models/gray_model_{x}', 'rb') as pickle_file:\n",
    "        gray_models.append(pickle.load(pickle_file))\n",
    "binary_models =[]\n",
    "for x in [20,120,360]:\n",
    "    with open(f'models/binary_model_{x}', 'rb') as pickle_file:\n",
    "        binary_models.append(pickle.load(pickle_file))\n",
    "\n",
    "chunk_size = 5000\n",
    "n = 50000\n",
    "for x in range(len(gray_models)):\n",
    "    out = gray_data[x]\n",
    "    arr = test_gray\n",
    "    for i in range(0, n//chunk_size):\n",
    "        data = gray_models[x].transform(arr[i*chunk_size : (i+1)*chunk_size])\n",
    "        out[i*chunk_size : (i+1)*chunk_size] = data\n",
    "        print(f'{i}\\t/\\t {n//chunk_size}',end='\\r',flush=True)\n",
    "    out.flush()\n",
    "    print(f'Gray Model {x} done')\n",
    "for x in range(len(binary_models)):\n",
    "    out = binary_data[x]\n",
    "    arr = test_binary\n",
    "    for i in range(0, n//chunk_size):\n",
    "        data = gray_models[x].transform(arr[i*chunk_size : (i+1)*chunk_size])\n",
    "        out[i*chunk_size : (i+1)*chunk_size] = data\n",
    "        print(f'{i}\\t/\\t {n//chunk_size}',end='\\r',flush=True)\n",
    "    out.flush()\n",
    "    print(f'Gray Model {x} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    }
   ],
   "source": [
    "test_gray.flush()\n",
    "test_binary.flush()\n",
    "test_target.flush()\n",
    "out_binary = np.memmap('data_full/image_data_binary.npy', mode='r', shape = (50000,275,210))\n",
    "# for x in out_binary[:5]:\n",
    "    # img = cv2.imread(x)\n",
    "\n",
    "    # cv2.imshow('image', x, cmap='gray')\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "# plt.imshow(out_binary[5], cmap='gray')\n",
    "cv2.imshow('image', out_binary[5])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0e1bddb7ed37f67f576e4a6a21b2408ebab9a006050dc6d038d31036c144c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
